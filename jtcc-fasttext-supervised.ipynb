{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016585,
     "end_time": "2021-01-02T13:24:37.699326",
     "exception": false,
     "start_time": "2021-01-02T13:24:37.682741",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 0. Introduction\n",
    "In earlier notebook(https://www.kaggle.com/anirbansen3027/jtcc-word2vec) we used Gensim for getting pretrained Word2Vec models/embedding vectors for the words used in the sentences, mapped them against the output variables \"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\" and used Multi Output Logistic Regression Classifier wrapper from sklearn to create Logistic Regression models for all the 6 output variables.\n",
    "\n",
    "In this one, we will be using fastText library for both generating embeddings for the sentences as well as text classification. Infact, it gives us an option of doing both in one go. The intuition part is going to be shorter than other methods as the documentation/ readings on the fastText are limited.\n",
    "\n",
    "**What is fastText?**\n",
    "\n",
    "In 2016, Facebook AI Research (FAIR) is open-sourced fastText, a library designed to help build scalable solutions for text representation and classification. fastText take the idea of word embeddings in Word2Vec a step ahead and learns representations\n",
    "for character n-grams, and to represent words as the sum of the n-gram vectors. Taking the word \"where\" and n = 3 as an example, it will be represented by the character n-grams: <wh, whe, her, ere, re>. Apart from txet representations in form of sub-word embeddings, it also provides an off-the-shelf classfication model which is optimized to work with these embedding and give fast results.\n",
    "\n",
    "**Why is fastText required?**\n",
    "\n",
    "fastText has 2 benifits over regular word2vec embeddings:\n",
    "\n",
    "*1. fastText helps in dealing with Out of Vocabulary(OOV) problem:*\n",
    "\n",
    "Word2Vec faces the problem of Out of vocabulary. Lets say we are training a Word2Vec model from scratch, we setup a vocabulary which contains of all the words in the training data. Now if we have a new word in the test data for which we might be needing embedding, the new missing word will be OOV. In word2vec we completely ignored such words. By using sub-word embeddings in fastText, we try to get an embedding for a word which is OOV as well\n",
    "\n",
    "*2. By using a distinct vector representation for each word, the Word2Vec model ignores the internal structure of words:*\n",
    "\n",
    "In word2vec each word is learned uniquely based on the context it appears in. For example  boxer and boxing are used in different contexts and there is no way we can capture the underlying similarity. Breaking it down to character n-gram helps\n",
    "\n",
    "**What are additional benifits of fastText?**\n",
    "\n",
    "Although fastText goes beyond word level to character-ngram level, It is extremely fast (and hence the name).Experiments show that fastText is often on par with deeplearning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation. We can train fastText on more than one billion words in less than ten minutes using a standard multicore CPU, and classify half a million sentences among 312K classes in less than a minute.\n",
    "\n",
    "Additionally, fastText provides word vectors for 157 languages trained on Wikipedia and Crawl (which is amazing).\n",
    "\n",
    "**How does fastText work?**\n",
    "\n",
    "*1. Creation of word embeddings*\n",
    "\n",
    "The subword model is based on the skipgram model from Word2Vec and instead of using the vector representations of words, an average of the vector representations of the character n-grams are used. Eveything else is quite similar to the skipgram model. \n",
    "\n",
    "*2. Text Classification*\n",
    "<img src=\"https://i.imgur.com/Gl1PiFO.png\" title=\"source: imgur.com\" width = 300/> \n",
    "Above image is taken from the actual paper \"Bag of Tricks for Efficient Text Classification\" where fastText for classification was introduced. fastText uses a shallow neural network similar to Word2Vec networks. We use the softmax function f to compute the probability distribution over the predefined classes.\n",
    "\n",
    "Infact, it uses something called Hierarchical softmax based on the Huffman coding tree (the most common word/alphabet is given the smallest code in short). So, in Hierarchical softmax probability of a node is always lower than the one of its parent. This helps both when we have a large number of classes and at testing time where we are searching for the most likely class. \n",
    "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20200921040227/treec.png\" width = 300/> \n",
    "For example, if Travel, Food and Indian Cuisines are 3 classes, and if Travel has a higher probability, we dont even need to calculate the probability for Food and Indian Cuisines. This saves reduces the complexity.\n",
    "\n",
    "Additionally it also uses word n-grams as additional features other than the embeddings to capture some partial information about the local word order which is otherwise very computationally expensive to cature in normal BagOfWords.\n",
    "\n",
    "Let's dive into the code then \n",
    "\n",
    "### Table of Contents:\n",
    "\n",
    "[1. Importing Libraries](#1)\n",
    "\n",
    "[2. Reading Dataset](#2)\n",
    "\n",
    "[3. Splitting Dataset into training and validation sets](#3)\n",
    "\n",
    "[4. Basic Preprocessing](#4)\n",
    "\n",
    "[5. Training and Validating fastText Classifier](#5)\n",
    "\n",
    "[6. Predicting and Submitting for Test Data](#6)\n",
    "\n",
    "[7. TODOs](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014298,
     "end_time": "2021-01-02T13:24:37.727836",
     "exception": false,
     "start_time": "2021-01-02T13:24:37.713538",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Importing Libraries <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-01-02T13:24:37.763204Z",
     "iopub.status.busy": "2021-01-02T13:24:37.762344Z",
     "iopub.status.idle": "2021-01-02T13:24:39.097087Z",
     "shell.execute_reply": "2021-01-02T13:24:39.096301Z"
    },
    "papermill": {
     "duration": 1.355049,
     "end_time": "2021-01-02T13:24:39.097259",
     "exception": false,
     "start_time": "2021-01-02T13:24:37.742210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "\n",
    "from fasttext import train_supervised\n",
    "\n",
    "#Sklearn Library\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013915,
     "end_time": "2021-01-02T13:24:39.127905",
     "exception": false,
     "start_time": "2021-01-02T13:24:39.113990",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.Reading Dataset <a class=\"anchor\" id=\"2\"></a>\n",
    "All the datasets are provided as zipped files. First we will have to unzip them and then read them into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-02T13:24:39.166653Z",
     "iopub.status.busy": "2021-01-02T13:24:39.165762Z",
     "iopub.status.idle": "2021-01-02T13:24:41.980799Z",
     "shell.execute_reply": "2021-01-02T13:24:41.980004Z"
    },
    "papermill": {
     "duration": 2.836405,
     "end_time": "2021-01-02T13:24:41.980927",
     "exception": false,
     "start_time": "2021-01-02T13:24:39.144522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "4 archives were successfully processed.\r\n"
     ]
    }
   ],
   "source": [
    "#unzipping all the zip folders and saving it /kaggle/working and saving the verbose in /dev/null to keep it quiet\n",
    "# -o for overwrite -d for destination directory of unzipped file\n",
    "!unzip -o '/kaggle/input/jigsaw-toxic-comment-classification-challenge/*.zip' -d /kaggle/working > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-02T13:24:42.020892Z",
     "iopub.status.busy": "2021-01-02T13:24:42.020023Z",
     "iopub.status.idle": "2021-01-02T13:24:44.084358Z",
     "shell.execute_reply": "2021-01-02T13:24:44.083702Z"
    },
    "papermill": {
     "duration": 2.08646,
     "end_time": "2021-01-02T13:24:44.084504",
     "exception": false,
     "start_time": "2021-01-02T13:24:41.998044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8) (153164, 2) (153164, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading input csv files\n",
    "train_text = pd.read_csv(\"train.csv\")\n",
    "test_text = pd.read_csv(\"test.csv\")\n",
    "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "print(train_text.shape, test_text.shape, sample_submission.shape)\n",
    "train_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014962,
     "end_time": "2021-01-02T13:24:44.115367",
     "exception": false,
     "start_time": "2021-01-02T13:24:44.100405",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Splitting Dataset into training and validation sets <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-02T13:24:44.165443Z",
     "iopub.status.busy": "2021-01-02T13:24:44.164700Z",
     "iopub.status.idle": "2021-01-02T13:24:44.204023Z",
     "shell.execute_reply": "2021-01-02T13:24:44.204624Z"
    },
    "papermill": {
     "duration": 0.073341,
     "end_time": "2021-01-02T13:24:44.204796",
     "exception": false,
     "start_time": "2021-01-02T13:24:44.131455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_cols = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "X = train_text.comment_text\n",
    "y = train_text[y_cols]\n",
    "\n",
    "train, val = train_test_split(train_text, shuffle = True, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015498,
     "end_time": "2021-01-02T13:24:44.236094",
     "exception": false,
     "start_time": "2021-01-02T13:24:44.220596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Basic Preprocessing <a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016244,
     "end_time": "2021-01-02T13:24:44.268154",
     "exception": false,
     "start_time": "2021-01-02T13:24:44.251910",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In terms of preprocessing we are doing the following steps:\n",
    "\n",
    "1. We are introducing spaces for some punctuations like ?, ., ) , ( , ! , and removed some just to make the text cleaner\n",
    "\n",
    "2. We have removed \\n as we can already see a lot of it in the texts\n",
    "\n",
    "3. We did some unicode normalization it order to handle some unicode issues that might arise\n",
    "\n",
    "4. This one being the most important, converting the binary labels for all output variables from 0 and 1 to \\__clas__0 and \\__class__1 as the fastText classifier needs it that way. We only need to do this for the training_data as the classifier will not look at the real labels of the validation data or the test data\n",
    "\n",
    "5. Shuffling the dataset to introduce some randomness and remove ordering (if present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-02T13:24:44.314302Z",
     "iopub.status.busy": "2021-01-02T13:24:44.309270Z",
     "iopub.status.idle": "2021-01-02T13:24:47.360323Z",
     "shell.execute_reply": "2021-01-02T13:24:47.359470Z"
    },
    "papermill": {
     "duration": 3.076038,
     "end_time": "2021-01-02T13:24:47.360485",
     "exception": false,
     "start_time": "2021-01-02T13:24:44.284447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lets do some cleaning of this text\n",
    "def clean_it(text,normalize=True):\n",
    "    # Replacing possible issues with data. We can add or reduce the replacemtent in this chain\n",
    "    s = str(text).replace(',',' ').replace('\"','').replace('\\'',' \\' ').replace('.',' . ').replace('(',' ( ').\\\n",
    "            replace(')',' ) ').replace('!',' ! ').replace('?',' ? ').replace(':',' ').replace(';',' ').lower()\n",
    "    s = s.replace(\"\\n\",\" \")\n",
    "    \n",
    "    # normalizing / encoding the text\n",
    "    if normalize:\n",
    "        s = s.normalize('NFKD').str.encode('ascii','ignore').str.decode('utf-8')\n",
    "    \n",
    "    return s\n",
    "\n",
    "# Now lets define a small function where we can use above cleaning on datasets\n",
    "def clean_df(data, cleanit= False, shuffleit=False, encodeit=False, label_prefix='__class__'):\n",
    "    # Defining the new data\n",
    "    df = data[['comment_text']].copy(deep=True)\n",
    "    for col in y_cols:\n",
    "        df[col] = label_prefix + data[col].astype(str) + ' '\n",
    "    \n",
    "    # cleaning it\n",
    "    if cleanit:\n",
    "        df['comment_text'] = df['comment_text'].apply(lambda x: clean_it(x,encodeit))\n",
    "    \n",
    "    # shuffling it\n",
    "    if shuffleit:\n",
    "        df.sample(frac=1).reset_index(drop=True)\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Transform the datasets using the above clean functions\n",
    "df_train_cleaned = clean_df(train, True, True)\n",
    "df_val_cleaned = clean_df(val, True, True, label_prefix='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-02T13:24:47.407131Z",
     "iopub.status.busy": "2021-01-02T13:24:47.406169Z",
     "iopub.status.idle": "2021-01-02T13:24:47.411655Z",
     "shell.execute_reply": "2021-01-02T13:24:47.411027Z"
    },
    "papermill": {
     "duration": 0.035318,
     "end_time": "2021-01-02T13:24:47.411774",
     "exception": false,
     "start_time": "2021-01-02T13:24:47.376456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141599</th>\n",
       "      <td>a quote   many psychometricians and behavio...</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86692</th>\n",
       "      <td>and right at the time of making such allegati...</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28863</th>\n",
       "      <td>formally not  de facto yes .  and in the end  ...</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14048</th>\n",
       "      <td>religious groups   why is the only religion is...</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78005</th>\n",
       "      <td>the doctor suggests it ' s probably something...</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "      <td>__class__0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text        toxic  \\\n",
       "141599     a quote   many psychometricians and behavio...  __class__0    \n",
       "86692    and right at the time of making such allegati...  __class__0    \n",
       "28863   formally not  de facto yes .  and in the end  ...  __class__0    \n",
       "14048   religious groups   why is the only religion is...  __class__0    \n",
       "78005    the doctor suggests it ' s probably something...  __class__0    \n",
       "\n",
       "       severe_toxic      obscene       threat       insult identity_hate  \n",
       "141599  __class__0   __class__0   __class__0   __class__0    __class__0   \n",
       "86692   __class__0   __class__0   __class__0   __class__0    __class__0   \n",
       "28863   __class__0   __class__0   __class__0   __class__0    __class__0   \n",
       "14048   __class__0   __class__0   __class__0   __class__0    __class__0   \n",
       "78005   __class__0   __class__0   __class__0   __class__0    __class__0   "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-02T13:24:47.459512Z",
     "iopub.status.busy": "2021-01-02T13:24:47.458394Z",
     "iopub.status.idle": "2021-01-02T13:24:47.463435Z",
     "shell.execute_reply": "2021-01-02T13:24:47.462909Z"
    },
    "papermill": {
     "duration": 0.035359,
     "end_time": "2021-01-02T13:24:47.463555",
     "exception": false,
     "start_time": "2021-01-02T13:24:47.428196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50446</th>\n",
       "      <td>and redirect the other names to it</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81571</th>\n",
       "      <td>sinebot1 please read the above comments .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25983</th>\n",
       "      <td>thank you for your very good answer .   i just...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39022</th>\n",
       "      <td>i think we need to ask who is likely to be v...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49431</th>\n",
       "      <td>orangemonster2k1|svrtvdude]]  ( vt )  23 26  3...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comment_text toxic severe_toxic  \\\n",
       "50446                 and redirect the other names to it    0            0    \n",
       "81571         sinebot1 please read the above comments .     0            0    \n",
       "25983  thank you for your very good answer .   i just...    0            0    \n",
       "39022    i think we need to ask who is likely to be v...    0            0    \n",
       "49431  orangemonster2k1|svrtvdude]]  ( vt )  23 26  3...    0            0    \n",
       "\n",
       "      obscene threat insult identity_hate  \n",
       "50446      0      0      0             0   \n",
       "81571      0      0      0             0   \n",
       "25983      0      0      0             0   \n",
       "39022      0      0      0             0   \n",
       "49431      0      0      0             0   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016729,
     "end_time": "2021-01-02T13:24:47.497457",
     "exception": false,
     "start_time": "2021-01-02T13:24:47.480728",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So, as mentioned earlier we have changed the label classes for the training dataset but not for the validation set as they wouldn't be looked at by the fastText classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016713,
     "end_time": "2021-01-02T13:24:47.531265",
     "exception": false,
     "start_time": "2021-01-02T13:24:47.514552",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Training and Validating fastText Classifier <a class=\"anchor\" id=\"5\"></a>\n",
    "\n",
    "* Since fastText classifier takes input a csv file with the text data and the class label, we can't use the Multi-Output Classifier wrapper we were using in earlier notebooks. So we will have to run a for loop to train separate models for each output variable and store predictions for each output variable in the validation set.\n",
    "\n",
    "* train_supervised is the function that is used for fastText classification. We can tune the learning parameters to improve the model.\n",
    "\n",
    "* There is no API till date which can take a validation set and give out probabilities for the positive case. We can only get probabilities for one sentence at a time. So, we run a for loop around each of the validation sentence and store the probabilities in a list. We need probabilties as the performance metric is ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-02T13:24:47.576170Z",
     "iopub.status.busy": "2021-01-02T13:24:47.575301Z",
     "iopub.status.idle": "2021-01-02T13:26:15.139958Z",
     "shell.execute_reply": "2021-01-02T13:26:15.136030Z"
    },
    "papermill": {
     "duration": 87.591702,
     "end_time": "2021-01-02T13:26:15.140160",
     "exception": false,
     "start_time": "2021-01-02T13:24:47.548458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f50a0af17b48a09f47d2f44a0f7c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Will contain all the predictions for validation set for all the output variables\n",
    "all_preds = []\n",
    "#Iterating over all output variables to create separate models\n",
    "for col in tqdm(y_cols):\n",
    "    #Path for saving the training dataset\n",
    "    train_file = '/kaggle/working/final_train.csv'\n",
    "    #Saving the Output Variable and the text data to a csv\n",
    "    df_train_cleaned[[col, \"comment_text\"]].to_csv(train_file, header=None, index=False, columns=[col, \"comment_text\"]) \n",
    "    #Training the model\n",
    "    model = train_supervised(input=train_file, label=\"__class__\", lr=1.0, epoch=2, loss='ova', wordNgrams=2, dim=200, thread=2, verbose=100)\n",
    "    #Predictions for validation sets for that ouput variable\n",
    "    col_preds = []\n",
    "    #Iterating over each sentence in the validation set\n",
    "    for text in df_val_cleaned[\"comment_text\"].values:\n",
    "        #Get the prediction for class 1\n",
    "        pred = model.predict(text, k = 2)[1][1]\n",
    "        #Append the prediction to the list of predictions for that output variable\n",
    "        col_preds.append(pred)\n",
    "    #Append the list of predictions for a output variable to the overall set of predictions for all columns\n",
    "    all_preds.append(col_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017851,
     "end_time": "2021-01-02T13:26:15.176937",
     "exception": false,
     "start_time": "2021-01-02T13:26:15.159086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we have got the predictions from the model on the validation set, let's look at the results/performance. Since, the competition uses mean ROC-AUC as the evaluation metric, we will be using the same in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-02T13:26:15.217335Z",
     "iopub.status.busy": "2021-01-02T13:26:15.216395Z",
     "iopub.status.idle": "2021-01-02T13:26:15.222894Z",
     "shell.execute_reply": "2021-01-02T13:26:15.223460Z"
    },
    "papermill": {
     "duration": 0.02835,
     "end_time": "2021-01-02T13:26:15.223608",
     "exception": false,
     "start_time": "2021-01-02T13:26:15.195258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function for calculating roc auc with given actual binary values across target variables and the probability score made by the model\n",
    "def accuracy(y_test, y_pred):\n",
    "    aucs = []\n",
    "    #Calculate the ROC-AUC for each of the target column\n",
    "    for col in range(y_test.shape[1]):\n",
    "        aucs.append(roc_auc_score(y_test[:,col],y_pred[:,col]))\n",
    "    return aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-02T13:26:15.264390Z",
     "iopub.status.busy": "2021-01-02T13:26:15.263369Z",
     "iopub.status.idle": "2021-01-02T13:26:15.414618Z",
     "shell.execute_reply": "2021-01-02T13:26:15.415185Z"
    },
    "papermill": {
     "duration": 0.173153,
     "end_time": "2021-01-02T13:26:15.415324",
     "exception": false,
     "start_time": "2021-01-02T13:26:15.242171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.764607758647555"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Actual Labels\n",
    "y_val_actuals = df_val_cleaned[y_cols].astype(\"int\").to_numpy()\n",
    "#Prediction probability - minor ordering\n",
    "all_preds_array = np.transpose(np.array(all_preds))\n",
    "#Calculate the mean of the ROC-AUC for each of the ouput variable\n",
    "mean_auc = mean(accuracy(y_val_actuals,all_preds_array))\n",
    "mean_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018818,
     "end_time": "2021-01-02T13:26:15.453142",
     "exception": false,
     "start_time": "2021-01-02T13:26:15.434324",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "ROC-AUC on the validation set tends to be around 0.77 which is much better than the Word2Vec model. Also, these are early results just on 2 epochs and not-tuned parameters. I think we can get even better results with better tuning. And also the learning and predictions were pretty quick.Apparently, Logistic Regression model that we used with BagOfWords took more time to converge while training than fastText."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018472,
     "end_time": "2021-01-02T13:26:15.490390",
     "exception": false,
     "start_time": "2021-01-02T13:26:15.471918",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Predicting and Submitting for Test Data <a class=\"anchor\" id=\"6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-02T13:26:15.532539Z",
     "iopub.status.busy": "2021-01-02T13:26:15.531544Z",
     "iopub.status.idle": "2021-01-02T13:27:10.067819Z",
     "shell.execute_reply": "2021-01-02T13:27:10.067095Z"
    },
    "papermill": {
     "duration": 54.558486,
     "end_time": "2021-01-02T13:27:10.067945",
     "exception": false,
     "start_time": "2021-01-02T13:26:15.509459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3450d70b3df247d3a56248197db9ecd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Merging the test dataset with sample_submission to have all the columns:\n",
    "#id,text_data and the target variables in one dataframe\n",
    "df_test = pd.merge(test_text, sample_submission, on = \"id\")\n",
    "# Preprocessing the test dataset as well\n",
    "df_test_cleaned = clean_df(df_test, True, True, label_prefix='')\n",
    "#Will contain all the predictions for validation set for all the output variables\n",
    "all_test_preds = []\n",
    "for col in tqdm(y_cols):\n",
    "    #Predictions for test sets for that ouput variable\n",
    "    col_preds = []\n",
    "    #Iterating over each sentence in the test set\n",
    "    for text in df_test_cleaned[\"comment_text\"].values:\n",
    "        #Get the prediction for class 1\n",
    "        pred = model.predict(text, k = 2)[1][1]\n",
    "        #Append the prediction to the list of predictions for that output variable\n",
    "        col_preds.append(pred)\n",
    "    #Append the list of predictions for a output variable to the overall set of predictions for all columns\n",
    "    all_test_preds.append(col_preds)\n",
    "#Prediction probability - minor ordering\n",
    "all_test_preds_array = np.transpose(np.array(all_test_preds))\n",
    "#Assign the predictions by the model in the final test dataset\n",
    "df_test[[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]] = all_test_preds_array\n",
    "#Drop Comment Text as the sample submission doesnt have it and wouldnt be expected\n",
    "df_test.drop([\"comment_text\"], axis = 1, inplace = True)\n",
    "#Save the dataset as a csv to submit it\n",
    "df_test.to_csv(\"sample_submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019649,
     "end_time": "2021-01-02T13:27:10.107354",
     "exception": false,
     "start_time": "2021-01-02T13:27:10.087705",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. TODOs <a class=\"anchor\" id=\"7\"></a>\n",
    "* Better Text Preprocessing Typo correction etc can be done to further improve the model\n",
    "* Try tuning the hyperparameters to get better results\n",
    "\n",
    "***Do upvote if you find it helpful üòÅ***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 158.270436,
   "end_time": "2021-01-02T13:27:10.234756",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-02T13:24:31.964320",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "12b7d08bb73247e98be84c9b0cc9b655": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "21344d7e508e4d0fbf7ebc9276037b8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_da98c16e3195445d93839c3a3df0fc3c",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_e3e60b7f890b4ad4858be6d1d689fe64",
       "value": " 6/6 [00:48&lt;00:00,  8.16s/it]"
      }
     },
     "27d408e6deda4c77903d0297e45def0f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4c5208a0a9de4a61afbabcc64f345a9c",
       "max": 6.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_70b7e74fdae54ffcba224ab4583a3a4a",
       "value": 6.0
      }
     },
     "3185838997494ecb9af256b731cb72c3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3450d70b3df247d3a56248197db9ecd7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_27d408e6deda4c77903d0297e45def0f",
        "IPY_MODEL_21344d7e508e4d0fbf7ebc9276037b8f"
       ],
       "layout": "IPY_MODEL_3185838997494ecb9af256b731cb72c3"
      }
     },
     "4c5208a0a9de4a61afbabcc64f345a9c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "60288903c3de4aa08b2aba9dae428bf7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "70b7e74fdae54ffcba224ab4583a3a4a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "7129763773e34b55afb88a22572521a5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "85fa0b7b1fca40cda38f588d4b601ab6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "a4f50a0af17b48a09f47d2f44a0f7c45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d3e0e122386f47ec859f966cdfa2a3a0",
        "IPY_MODEL_db33b2b2d8ad427b928ba38e10d3b21a"
       ],
       "layout": "IPY_MODEL_12b7d08bb73247e98be84c9b0cc9b655"
      }
     },
     "d3e0e122386f47ec859f966cdfa2a3a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_60288903c3de4aa08b2aba9dae428bf7",
       "max": 6.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_85fa0b7b1fca40cda38f588d4b601ab6",
       "value": 6.0
      }
     },
     "da98c16e3195445d93839c3a3df0fc3c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "db33b2b2d8ad427b928ba38e10d3b21a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7129763773e34b55afb88a22572521a5",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_db6752d81e9d44d4accb396cddaf69b0",
       "value": " 6/6 [01:27&lt;00:00, 14.59s/it]"
      }
     },
     "db6752d81e9d44d4accb396cddaf69b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e3e60b7f890b4ad4858be6d1d689fe64": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
